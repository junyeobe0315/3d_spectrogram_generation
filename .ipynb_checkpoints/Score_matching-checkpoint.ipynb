{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "amber-central",
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils.load_data import *\n",
    "import numpy as np\n",
    "\n",
    "BCIC_dataset = load_BCIC(\n",
    "train_sub=[1,2,3,4,5,6,7,8],\n",
    "test_sub=[9],\n",
    "alg_name = 'Tensor_CSPNet',\n",
    "scenario = 'subject-independent'\n",
    ")\n",
    "\n",
    "train_x, train_y, test_x, test_y = BCIC_dataset.generate_training_valid_test_set_subject_independent()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "alternate-syria",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x_normalized = np.zeros_like(train_x)\n",
    "\n",
    "for i in range(train_x.shape[0]):\n",
    "    tensor = train_x[i]\n",
    "    l2_norm = np.linalg.norm(tensor)\n",
    "    train_x_normalized[i] = tensor / l2_norm\n",
    "\n",
    "data_x_0, data_y_0 = [], []\n",
    "data_x_1, data_y_1 = [], []\n",
    "data_x_2, data_y_2 = [], []\n",
    "data_x_3, data_y_3 = [], []\n",
    "    \n",
    "for idx, i in enumerate(train_y):\n",
    "    lab = int(i)\n",
    "    if lab == 0:\n",
    "        data_x_0.append(train_x_normalized[idx])\n",
    "        data_y_0.append(i)\n",
    "    if lab == 1:\n",
    "        data_x_1.append(train_x_normalized[idx])\n",
    "        data_y_1.append(i)\n",
    "    if lab == 2:\n",
    "        data_x_2.append(train_x_normalized[idx])\n",
    "        data_y_2.append(i)\n",
    "    if lab == 3:\n",
    "        data_x_3.append(train_x_normalized[idx])\n",
    "        data_y_3.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "sought-original",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 9, 22, 22])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch \n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class BCI_datset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x = x\n",
    "        self.y = y\n",
    "    def __len__(self):\n",
    "        return len(self.y)\n",
    "    def __getitem__(self, idx):\n",
    "        return torch.tensor(self.x[idx]).to(torch.float32), self.y[idx]\n",
    "    \n",
    "dataset0 = BCI_datset(data_x_0, data_y_0)\n",
    "# dataset1 = BCI_datset(data_x_1, data_y_1)\n",
    "# dataset2 = BCI_datset(data_x_2, data_y_2)\n",
    "# dataset3 = BCI_datset(data_x_3, data_y_3)\n",
    "\n",
    "dataloader0 = DataLoader(dataset0, batch_size=128, shuffle=True, num_workers=1)\n",
    "# dataloader1 = DataLoader(dataset1, batch_size=32, shuffle=True, num_workers=1)\n",
    "# dataloader2 = DataLoader(dataset2, batch_size=32, shuffle=True, num_workers=1)\n",
    "# dataloader3 = DataLoader(dataset3, batch_size=32, shuffle=True, num_workers=1)\n",
    "\n",
    "dataset0.__getitem__(0)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "perceived-criminal",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from lib.sdes import VariancePreservingSDE, PluginReverseSDE\n",
    "from lib.plotting import get_grid\n",
    "from lib.flows.elemwise import LogitTransform\n",
    "from lib.helpers import logging, create\n",
    "import json\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "\n",
    "class GaussianFourierProjection(nn.Module):\n",
    "    \"\"\"Gaussian random features for encoding time steps.\"\"\"  \n",
    "    def __init__(self, embed_dim, scale=30.):\n",
    "        super().__init__()\n",
    "        # Randomly sample weights during initialization. These weights are fixed \n",
    "        # during optimization and are not trainable.\n",
    "        self.W = nn.Parameter(torch.randn(embed_dim // 2) * scale, requires_grad=False)\n",
    "    def forward(self, x):\n",
    "        x_proj = x[:, None] * self.W[None, :] * 2 * np.pi\n",
    "        return torch.cat([torch.sin(x_proj), torch.cos(x_proj)], dim=-1)\n",
    "\n",
    "\n",
    "class Dense(nn.Module):\n",
    "    \"\"\"A fully connected layer that reshapes outputs to feature maps.\"\"\"\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super().__init__()\n",
    "        self.dense = nn.Linear(input_dim, output_dim)\n",
    "    def forward(self, x):\n",
    "        return self.dense(x)[..., None, None]\n",
    "\n",
    "\n",
    "class ScoreNet(nn.Module):\n",
    "    \"\"\"A time-dependent score-based model built upon U-Net architecture.\"\"\"\n",
    "\n",
    "    def __init__(self, marginal_prob_std, channels=[32, 64, 128, 256], embed_dim=256):\n",
    "        \"\"\"Initialize a time-dependent score-based network.\n",
    "\n",
    "        Args:\n",
    "          marginal_prob_std: A function that takes time t and gives the standard\n",
    "            deviation of the perturbation kernel p_{0t}(x(t) | x(0)).\n",
    "          channels: The number of channels for feature maps of each resolution.\n",
    "          embed_dim: The dimensionality of Gaussian random feature embeddings.\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        # Gaussian random feature embedding layer for time\n",
    "        self.embed = nn.Sequential(GaussianFourierProjection(embed_dim=embed_dim),\n",
    "             nn.Linear(embed_dim, embed_dim))\n",
    "        # Encoding layers where the resolution decreases\n",
    "        self.conv1 = torch.nn.Conv3d(in_channels=1, out_channels=32, kernel_size=(3,22,22), padding=(0,0,0), bias=False)\n",
    "        self.dense1 = Dense(embed_dim, channels[0])\n",
    "        self.gnorm1 = nn.GroupNorm(4, num_channels=channels[0])\n",
    "        self.conv2 = torch.nn.Conv3d(in_channels=32, out_channels=64, kernel_size=(3,1,1), padding=(0,0,0), bias=False)\n",
    "        self.dense2 = Dense(embed_dim, channels[1])\n",
    "        self.gnorm2 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "        self.conv3 = torch.nn.Conv3d(in_channels=64, out_channels=128, kernel_size=(3,1,1), padding=(0,0,0), bias=False)\n",
    "        self.dense3 = Dense(embed_dim, channels[2])\n",
    "        self.gnorm3 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        self.conv4 = torch.nn.Conv3d(in_channels=128, out_channels=256, kernel_size=(3,1,1), padding=(0,0,0), bias=False)\n",
    "        self.dense4 = Dense(embed_dim, channels[3])\n",
    "        self.gnorm4 = nn.GroupNorm(32, num_channels=channels[3])    \n",
    "\n",
    "        # Decoding layers where the resolution increases\n",
    "        self.tconv4 = torch.nn.ConvTranspose3d(in_channels=256, out_channels=128, kernel_size= (3,1,1), bias=False)\n",
    "        self.dense5 = Dense(embed_dim, channels[2])\n",
    "        self.tgnorm4 = nn.GroupNorm(32, num_channels=channels[2])\n",
    "        self.tconv3 = torch.nn.ConvTranspose3d(in_channels=128, out_channels=64, kernel_size= (4,1,1), padding=(2,0,0), bias=False)    \n",
    "        self.dense6 = Dense(embed_dim, channels[1])\n",
    "        self.tgnorm3 = nn.GroupNorm(32, num_channels=channels[1])\n",
    "        self.tconv2 = torch.nn.ConvTranspose3d(in_channels=64, out_channels=32, kernel_size= (2,1,1), padding=(2,0,0), bias=False)   \n",
    "        self.dense7 = Dense(embed_dim, channels[0])\n",
    "        self.tgnorm2 = nn.GroupNorm(32, num_channels=channels[0])\n",
    "        self.tconv1 = torch.nn.ConvTranspose3d(in_channels=32, out_channels=1, kernel_size= (6,22,22), padding=(5,0,0), bias=False)\n",
    "\n",
    "        # The swish activation function\n",
    "        self.act = lambda x: x * torch.sigmoid(x)\n",
    "  \n",
    "    def forward(self, x, t): \n",
    "        # Obtain the Gaussian random feature embedding for t   \n",
    "        embed = self.act(self.embed(t))    \n",
    "        # Encoding path\n",
    "        h1 = self.conv1(x)    \n",
    "        ## Incorporate information from t\n",
    "        h1 += self.dense1(embed)\n",
    "        ## Group normalization\n",
    "        h1 = self.gnorm1(h1)\n",
    "        h1 = self.act(h1)\n",
    "        h2 = self.conv2(h1)\n",
    "        h2 += self.dense2(embed)\n",
    "        h2 = self.gnorm2(h2)\n",
    "        h2 = self.act(h2)\n",
    "        h3 = self.conv3(h2)\n",
    "        h3 += self.dense3(embed)\n",
    "        h3 = self.gnorm3(h3)\n",
    "        h3 = self.act(h3)\n",
    "        h4 = self.conv4(h3)\n",
    "        h4 += self.dense4(embed)\n",
    "        h4 = self.gnorm4(h4)\n",
    "        h4 = self.act(h4)\n",
    "\n",
    "        # Decoding path\n",
    "        h = self.tconv4(h4)\n",
    "        ## Skip connection from the encoding path\n",
    "        h += self.dense5(embed)\n",
    "        h = self.tgnorm4(h)\n",
    "        h = self.act(h)\n",
    "        h = self.tconv3(torch.cat([h, h3], dim=1))\n",
    "        h += self.dense6(embed)\n",
    "        h = self.tgnorm3(h)\n",
    "        h = self.act(h)\n",
    "        h = self.tconv2(torch.cat([h, h2], dim=1))\n",
    "        h += self.dense7(embed)\n",
    "        h = self.tgnorm2(h)\n",
    "        h = self.act(h)\n",
    "        h = self.tconv1(torch.cat([h, h1], dim=1))\n",
    "\n",
    "        h = h / self.marginal_prob_std(t)[:, None, None, None]\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "caroline-planner",
   "metadata": {},
   "outputs": [],
   "source": [
    "import functools\n",
    "device = 'cuda' #@param ['cuda', 'cpu'] {'type':'string'}\n",
    "\n",
    "def marginal_prob_std(t, sigma):\n",
    "    \"\"\"Compute the mean and standard deviation of $p_{0t}(x(t) | x(0))$.\n",
    "\n",
    "    Args:    \n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.  \n",
    "\n",
    "    Returns:\n",
    "    The standard deviation.\n",
    "    \"\"\"    \n",
    "    t = torch.tensor(t, device=device)\n",
    "    return torch.sqrt((sigma**(2 * t) - 1.) / 2. / np.log(sigma))\n",
    "\n",
    "def diffusion_coeff(t, sigma):\n",
    "    \"\"\"Compute the diffusion coefficient of our SDE.\n",
    "\n",
    "    Args:\n",
    "    t: A vector of time steps.\n",
    "    sigma: The $\\sigma$ in our SDE.\n",
    "\n",
    "    Returns:\n",
    "    The vector of diffusion coefficients.\n",
    "    \"\"\"\n",
    "    return torch.tensor(sigma**t, device=device)\n",
    "  \n",
    "def loss_fn(model, x, marginal_prob_std, eps=1e-5):\n",
    "    \"\"\"The loss function for training score-based generative models.\n",
    "\n",
    "    Args:\n",
    "    model: A PyTorch model instance that represents a \n",
    "      time-dependent score-based model.\n",
    "    x: A mini-batch of training data.    \n",
    "    marginal_prob_std: A function that gives the standard deviation of \n",
    "      the perturbation kernel.\n",
    "    eps: A tolerance value for numerical stability.\n",
    "    \"\"\"\n",
    "    random_t = torch.rand(x.shape[0], device=x.device) * (1. - eps) + eps  \n",
    "    z = torch.randn_like(x)\n",
    "    std = marginal_prob_std(random_t)\n",
    "    perturbed_x = x + z * std[:, None, None, None, None]\n",
    "    score = model(perturbed_x, random_t)\n",
    "    loss = torch.mean(torch.sum((score * std[:, None, None, None] + z)**2, dim=(1,2,3)))\n",
    "    return loss\n",
    "\n",
    "sigma =  25.0#@param {'type':'number'}\n",
    "marginal_prob_std_fn = functools.partial(marginal_prob_std, sigma=sigma)\n",
    "diffusion_coeff_fn = functools.partial(diffusion_coeff, sigma=sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "declared-queue",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9e610a888d854f58aa7a9cd102d64048",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_8731/560539497.py:14: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  t = torch.tensor(t, device=device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 1, 9, 22, 22])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (7) must match the size of tensor b (32) at non-singleton dimension 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 25\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m x, y \u001b[38;5;129;01min\u001b[39;00m dataloader0:\n\u001b[1;32m     24\u001b[0m     x \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mto(device)    \n\u001b[0;32m---> 25\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[43mloss_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscore_model\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmarginal_prob_std_fn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     26\u001b[0m     optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[1;32m     27\u001b[0m     loss\u001b[38;5;241m.\u001b[39mbackward()    \n",
      "Cell \u001b[0;32mIn[26], line 44\u001b[0m, in \u001b[0;36mloss_fn\u001b[0;34m(model, x, marginal_prob_std, eps)\u001b[0m\n\u001b[1;32m     42\u001b[0m std \u001b[38;5;241m=\u001b[39m marginal_prob_std(random_t)\n\u001b[1;32m     43\u001b[0m perturbed_x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m z \u001b[38;5;241m*\u001b[39m std[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m]\n\u001b[0;32m---> 44\u001b[0m score \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mperturbed_x\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrandom_t\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     45\u001b[0m loss \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmean(torch\u001b[38;5;241m.\u001b[39msum((score \u001b[38;5;241m*\u001b[39m std[:, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m] \u001b[38;5;241m+\u001b[39m z)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m2\u001b[39m, dim\u001b[38;5;241m=\u001b[39m(\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m2\u001b[39m,\u001b[38;5;241m3\u001b[39m)))\n\u001b[1;32m     46\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/parallel/data_parallel.py:169\u001b[0m, in \u001b[0;36mDataParallel.forward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m ({},)\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 169\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    170\u001b[0m replicas \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplicate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodule, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdevice_ids[:\u001b[38;5;28mlen\u001b[39m(inputs)])\n\u001b[1;32m    171\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparallel_apply(replicas, inputs, kwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;66;03m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[38;5;241m=\u001b[39m [], []\n",
      "Cell \u001b[0;32mIn[21], line 89\u001b[0m, in \u001b[0;36mScoreNet.forward\u001b[0;34m(self, x, t)\u001b[0m\n\u001b[1;32m     87\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconv1(x)    \n\u001b[1;32m     88\u001b[0m \u001b[38;5;66;03m## Incorporate information from t\u001b[39;00m\n\u001b[0;32m---> 89\u001b[0m h1 \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdense1(embed)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;66;03m## Group normalization\u001b[39;00m\n\u001b[1;32m     91\u001b[0m h1 \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgnorm1(h1)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: The size of tensor a (7) must match the size of tensor b (32) at non-singleton dimension 2"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import functools\n",
    "from torch.optim import Adam\n",
    "from torch.utils.data import DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "import tqdm.notebook as tqdm\n",
    "\n",
    "\n",
    "score_model = torch.nn.DataParallel(ScoreNet(marginal_prob_std=marginal_prob_std_fn))\n",
    "score_model = score_model.to(device)\n",
    "\n",
    "n_epochs =   50\n",
    "\n",
    "lr=1e-4 \n",
    "\n",
    "\n",
    "optimizer = Adam(score_model.parameters(), lr=lr)\n",
    "tqdm_epoch = tqdm.tnrange(n_epochs)\n",
    "for epoch in tqdm_epoch:\n",
    "    avg_loss = 0.\n",
    "    num_items = 0\n",
    "    for x, y in dataloader0:\n",
    "        x = x.to(device)    \n",
    "        loss = loss_fn(score_model, x, marginal_prob_std_fn)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()    \n",
    "        optimizer.step()\n",
    "        avg_loss += loss.item() * x.shape[0]\n",
    "        num_items += x.shape[0]\n",
    "    # Print the averaged training loss so far.\n",
    "    tqdm_epoch.set_description('Average Loss: {:5f}'.format(avg_loss / num_items))\n",
    "    # Update the checkpoint after each epoch of training.\n",
    "    torch.save(score_model.state_dict(), 'ckpt.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "seven-grocery",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
