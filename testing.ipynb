{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "intense-trouble",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/junyeobe/.local/lib/python3.9/site-packages/requests/__init__.py:102: RequestsDependencyWarning: urllib3 (1.26.13) or chardet (5.1.0)/charset_normalizer (2.0.12) doesn't match a supported version!\n",
      "  warnings.warn(\"urllib3 ({}) or chardet ({})/charset_normalizer ({}) doesn't match a supported \"\n",
      "2023-05-16 18:21:15.159511: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-05-16 18:21:15.659121: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "2023-05-16 18:21:27.979361: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:28.000713: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:28.000966: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:28.002423: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:28.002621: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:28.002792: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:29.581417: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:29.581623: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:29.581636: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1722] Could not identify NUMA node of platform GPU id 0, defaulting to 0.  Your kernel may not have been built with NUMA support.\n",
      "2023-05-16 18:21:29.581826: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:982] could not open file to read NUMA node: /sys/bus/pci/devices/0000:01:00.0/numa_node\n",
      "Your kernel may have been built without NUMA support.\n",
      "2023-05-16 18:21:29.581863: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1635] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 4834 MB memory:  -> device: 0, name: NVIDIA GeForce RTX 3070, pci bus id: 0000:01:00.0, compute capability: 8.6\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-16 18:21:38.718727: E tensorflow/core/grappler/optimizers/meta_optimizer.cc:954] layout failed: INVALID_ARGUMENT: Size of values 0 does not match size of permutation 4 @ fanin shape inmodel/dropout/dropout/SelectV2-2-TransposeNHWCToNCHW-LayoutOptimizer\n",
      "2023-05-16 18:21:40.945181: I tensorflow/compiler/xla/stream_executor/cuda/cuda_dnn.cc:424] Loaded cuDNN version 8700\n",
      "2023-05-16 18:21:41.708407: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-16 18:21:42.085401: I tensorflow/compiler/xla/stream_executor/cuda/cuda_blas.cc:637] TensorFloat-32 will be used for the matrix multiplication. This will only be logged once.\n",
      "2023-05-16 18:21:42.152994: I tensorflow/compiler/xla/service/service.cc:169] XLA service 0x7f59ebb83070 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "2023-05-16 18:21:42.153031: I tensorflow/compiler/xla/service/service.cc:177]   StreamExecutor device (0): NVIDIA GeForce RTX 3070, Compute Capability 8.6\n",
      "2023-05-16 18:21:42.156785: I tensorflow/compiler/mlir/tensorflow/utils/dump_mlir_util.cc:269] disabling MLIR crash reproducer, set env var `MLIR_CRASH_REPRODUCER_DIRECTORY` to enable.\n",
      "2023-05-16 18:21:42.270246: I tensorflow/tsl/platform/default/subprocess.cc:304] Start cannot spawn child process: No such file or directory\n",
      "2023-05-16 18:21:42.308921: I ./tensorflow/compiler/jit/device_compiler.h:180] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 27s 61ms/step - loss: 1.3729 - accuracy: 0.3062 - val_loss: 1.3680 - val_accuracy: 0.2639\n",
      "Epoch 2/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 1.2858 - accuracy: 0.4067 - val_loss: 1.3154 - val_accuracy: 0.3177\n",
      "Epoch 3/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 1.1864 - accuracy: 0.4876 - val_loss: 1.2088 - val_accuracy: 0.4358\n",
      "Epoch 4/1000\n",
      "72/72 [==============================] - 3s 49ms/step - loss: 1.1129 - accuracy: 0.5352 - val_loss: 1.1241 - val_accuracy: 0.4740\n",
      "Epoch 5/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 1.0445 - accuracy: 0.5738 - val_loss: 1.0585 - val_accuracy: 0.5503\n",
      "Epoch 6/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.9906 - accuracy: 0.6007 - val_loss: 0.8208 - val_accuracy: 0.6997\n",
      "Epoch 7/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.9374 - accuracy: 0.6274 - val_loss: 0.6994 - val_accuracy: 0.7448\n",
      "Epoch 8/1000\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.9039 - accuracy: 0.6474 - val_loss: 0.6932 - val_accuracy: 0.7465\n",
      "Epoch 9/1000\n",
      "72/72 [==============================] - 3s 49ms/step - loss: 0.8632 - accuracy: 0.6576 - val_loss: 0.6195 - val_accuracy: 0.7569\n",
      "Epoch 10/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.8404 - accuracy: 0.6645 - val_loss: 0.6589 - val_accuracy: 0.7465\n",
      "Epoch 11/1000\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.8064 - accuracy: 0.6936 - val_loss: 0.6056 - val_accuracy: 0.7812\n",
      "Epoch 12/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.7894 - accuracy: 0.6912 - val_loss: 0.5781 - val_accuracy: 0.7899\n",
      "Epoch 13/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.7572 - accuracy: 0.7042 - val_loss: 0.5441 - val_accuracy: 0.8160\n",
      "Epoch 14/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.7364 - accuracy: 0.7224 - val_loss: 0.5692 - val_accuracy: 0.7760\n",
      "Epoch 15/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.7218 - accuracy: 0.7240 - val_loss: 0.5713 - val_accuracy: 0.7847\n",
      "Epoch 16/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.6979 - accuracy: 0.7296 - val_loss: 0.5718 - val_accuracy: 0.7778\n",
      "Epoch 17/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.6854 - accuracy: 0.7400 - val_loss: 0.5248 - val_accuracy: 0.8090\n",
      "Epoch 18/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.6732 - accuracy: 0.7359 - val_loss: 0.6717 - val_accuracy: 0.7500\n",
      "Epoch 19/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.6692 - accuracy: 0.7428 - val_loss: 0.5230 - val_accuracy: 0.8108\n",
      "Epoch 20/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.6583 - accuracy: 0.7470 - val_loss: 0.5457 - val_accuracy: 0.7847\n",
      "Epoch 21/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.6327 - accuracy: 0.7600 - val_loss: 0.5121 - val_accuracy: 0.8038\n",
      "Epoch 22/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.6306 - accuracy: 0.7546 - val_loss: 0.5143 - val_accuracy: 0.8090\n",
      "Epoch 23/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.6298 - accuracy: 0.7600 - val_loss: 0.5057 - val_accuracy: 0.8142\n",
      "Epoch 24/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.6097 - accuracy: 0.7648 - val_loss: 0.5828 - val_accuracy: 0.7795\n",
      "Epoch 25/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.6107 - accuracy: 0.7713 - val_loss: 0.5592 - val_accuracy: 0.7917\n",
      "Epoch 26/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.5975 - accuracy: 0.7719 - val_loss: 0.5785 - val_accuracy: 0.7708\n",
      "Epoch 27/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5991 - accuracy: 0.7758 - val_loss: 0.5174 - val_accuracy: 0.8021\n",
      "Epoch 28/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.5980 - accuracy: 0.7704 - val_loss: 0.5004 - val_accuracy: 0.8177\n",
      "Epoch 29/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5833 - accuracy: 0.7789 - val_loss: 0.4977 - val_accuracy: 0.8021\n",
      "Epoch 30/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5701 - accuracy: 0.7799 - val_loss: 0.5862 - val_accuracy: 0.7812\n",
      "Epoch 31/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5709 - accuracy: 0.7767 - val_loss: 0.5122 - val_accuracy: 0.8003\n",
      "Epoch 32/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5658 - accuracy: 0.7847 - val_loss: 0.4906 - val_accuracy: 0.8038\n",
      "Epoch 33/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5513 - accuracy: 0.7865 - val_loss: 0.5324 - val_accuracy: 0.8108\n",
      "Epoch 34/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.5399 - accuracy: 0.7982 - val_loss: 0.4757 - val_accuracy: 0.8125\n",
      "Epoch 35/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.5350 - accuracy: 0.7975 - val_loss: 0.5670 - val_accuracy: 0.7760\n",
      "Epoch 36/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.5318 - accuracy: 0.7973 - val_loss: 0.4769 - val_accuracy: 0.8160\n",
      "Epoch 37/1000\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.5275 - accuracy: 0.8003 - val_loss: 0.4431 - val_accuracy: 0.8299\n",
      "Epoch 38/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.5271 - accuracy: 0.8012 - val_loss: 0.5504 - val_accuracy: 0.7778\n",
      "Epoch 39/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.5216 - accuracy: 0.8066 - val_loss: 0.4656 - val_accuracy: 0.8264\n",
      "Epoch 40/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.5068 - accuracy: 0.8082 - val_loss: 0.4181 - val_accuracy: 0.8490\n",
      "Epoch 41/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.5113 - accuracy: 0.8056 - val_loss: 0.4708 - val_accuracy: 0.8125\n",
      "Epoch 42/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4925 - accuracy: 0.8118 - val_loss: 0.5159 - val_accuracy: 0.8003\n",
      "Epoch 43/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4952 - accuracy: 0.8049 - val_loss: 0.5144 - val_accuracy: 0.7951\n",
      "Epoch 44/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.4955 - accuracy: 0.8147 - val_loss: 0.4300 - val_accuracy: 0.8333\n",
      "Epoch 45/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4818 - accuracy: 0.8181 - val_loss: 0.4446 - val_accuracy: 0.8229\n",
      "Epoch 46/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4794 - accuracy: 0.8197 - val_loss: 0.5115 - val_accuracy: 0.8021\n",
      "Epoch 47/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4708 - accuracy: 0.8240 - val_loss: 0.4857 - val_accuracy: 0.8194\n",
      "Epoch 48/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4640 - accuracy: 0.8255 - val_loss: 0.5704 - val_accuracy: 0.7865\n",
      "Epoch 49/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4730 - accuracy: 0.8260 - val_loss: 0.4948 - val_accuracy: 0.7986\n",
      "Epoch 50/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.4668 - accuracy: 0.8247 - val_loss: 0.5185 - val_accuracy: 0.8073\n",
      "Epoch 51/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4662 - accuracy: 0.8275 - val_loss: 0.5538 - val_accuracy: 0.7899\n",
      "Epoch 52/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4643 - accuracy: 0.8264 - val_loss: 0.5310 - val_accuracy: 0.7830\n",
      "Epoch 53/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4624 - accuracy: 0.8264 - val_loss: 0.5146 - val_accuracy: 0.7986\n",
      "Epoch 54/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4562 - accuracy: 0.8264 - val_loss: 0.5574 - val_accuracy: 0.7882\n",
      "Epoch 55/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.4463 - accuracy: 0.8312 - val_loss: 0.5284 - val_accuracy: 0.7917\n",
      "Epoch 56/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4458 - accuracy: 0.8292 - val_loss: 0.4953 - val_accuracy: 0.8003\n",
      "Epoch 57/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.4343 - accuracy: 0.8414 - val_loss: 0.5878 - val_accuracy: 0.7726\n",
      "Epoch 58/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4386 - accuracy: 0.8351 - val_loss: 0.4823 - val_accuracy: 0.8056\n",
      "Epoch 59/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.4212 - accuracy: 0.8448 - val_loss: 0.5209 - val_accuracy: 0.7934\n",
      "Epoch 60/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.4431 - accuracy: 0.8346 - val_loss: 0.4912 - val_accuracy: 0.8021\n",
      "Epoch 61/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.4262 - accuracy: 0.8438 - val_loss: 0.5540 - val_accuracy: 0.7882\n",
      "Epoch 62/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4132 - accuracy: 0.8403 - val_loss: 0.4992 - val_accuracy: 0.8142\n",
      "Epoch 63/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4354 - accuracy: 0.8301 - val_loss: 0.4711 - val_accuracy: 0.8281\n",
      "Epoch 64/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4199 - accuracy: 0.8411 - val_loss: 0.4410 - val_accuracy: 0.8108\n",
      "Epoch 65/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.4310 - accuracy: 0.8388 - val_loss: 0.5777 - val_accuracy: 0.7743\n",
      "Epoch 66/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.4195 - accuracy: 0.8396 - val_loss: 0.4879 - val_accuracy: 0.8056\n",
      "Epoch 67/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.4016 - accuracy: 0.8498 - val_loss: 0.5188 - val_accuracy: 0.7847\n",
      "Epoch 68/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.4034 - accuracy: 0.8500 - val_loss: 0.5390 - val_accuracy: 0.7882\n",
      "Epoch 69/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4085 - accuracy: 0.8455 - val_loss: 0.5566 - val_accuracy: 0.7691\n",
      "Epoch 70/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.4160 - accuracy: 0.8487 - val_loss: 0.4882 - val_accuracy: 0.8142\n",
      "Epoch 71/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.3894 - accuracy: 0.8561 - val_loss: 0.4807 - val_accuracy: 0.8177\n",
      "Epoch 72/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.4106 - accuracy: 0.8492 - val_loss: 0.4906 - val_accuracy: 0.8125\n",
      "Epoch 73/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.3917 - accuracy: 0.8496 - val_loss: 0.6326 - val_accuracy: 0.7448\n",
      "Epoch 74/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.3971 - accuracy: 0.8535 - val_loss: 0.4920 - val_accuracy: 0.8056\n",
      "Epoch 75/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3829 - accuracy: 0.8609 - val_loss: 0.4856 - val_accuracy: 0.8160\n",
      "Epoch 76/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3885 - accuracy: 0.8550 - val_loss: 0.5423 - val_accuracy: 0.7917\n",
      "Epoch 77/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3755 - accuracy: 0.8605 - val_loss: 0.6280 - val_accuracy: 0.7656\n",
      "Epoch 78/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.3884 - accuracy: 0.8566 - val_loss: 0.5277 - val_accuracy: 0.7847\n",
      "Epoch 79/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3747 - accuracy: 0.8611 - val_loss: 0.5100 - val_accuracy: 0.8021\n",
      "Epoch 80/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3655 - accuracy: 0.8648 - val_loss: 0.5139 - val_accuracy: 0.8038\n",
      "Epoch 81/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3589 - accuracy: 0.8672 - val_loss: 0.5309 - val_accuracy: 0.7830\n",
      "Epoch 82/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.3727 - accuracy: 0.8681 - val_loss: 0.5788 - val_accuracy: 0.7743\n",
      "Epoch 83/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3751 - accuracy: 0.8596 - val_loss: 0.4785 - val_accuracy: 0.8073\n",
      "Epoch 84/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3786 - accuracy: 0.8622 - val_loss: 0.5331 - val_accuracy: 0.7917\n",
      "Epoch 85/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.3651 - accuracy: 0.8709 - val_loss: 0.4910 - val_accuracy: 0.8108\n",
      "Epoch 86/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3492 - accuracy: 0.8724 - val_loss: 0.4387 - val_accuracy: 0.8333\n",
      "Epoch 87/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3569 - accuracy: 0.8620 - val_loss: 0.5057 - val_accuracy: 0.8003\n",
      "Epoch 88/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3458 - accuracy: 0.8707 - val_loss: 0.6330 - val_accuracy: 0.7622\n",
      "Epoch 89/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.3736 - accuracy: 0.8613 - val_loss: 0.5167 - val_accuracy: 0.8003\n",
      "Epoch 90/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3452 - accuracy: 0.8711 - val_loss: 0.5753 - val_accuracy: 0.7726\n",
      "Epoch 91/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.3611 - accuracy: 0.8694 - val_loss: 0.6319 - val_accuracy: 0.7517\n",
      "Epoch 92/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3499 - accuracy: 0.8711 - val_loss: 0.5079 - val_accuracy: 0.8021\n",
      "Epoch 93/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3409 - accuracy: 0.8698 - val_loss: 0.4934 - val_accuracy: 0.8142\n",
      "Epoch 94/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3427 - accuracy: 0.8743 - val_loss: 0.5338 - val_accuracy: 0.7969\n",
      "Epoch 95/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3457 - accuracy: 0.8737 - val_loss: 0.5661 - val_accuracy: 0.7899\n",
      "Epoch 96/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.3571 - accuracy: 0.8655 - val_loss: 0.4511 - val_accuracy: 0.8125\n",
      "Epoch 97/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.3394 - accuracy: 0.8774 - val_loss: 0.5188 - val_accuracy: 0.7917\n",
      "Epoch 98/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3369 - accuracy: 0.8748 - val_loss: 0.5410 - val_accuracy: 0.7917\n",
      "Epoch 99/1000\n",
      "72/72 [==============================] - 4s 51ms/step - loss: 0.3354 - accuracy: 0.8739 - val_loss: 0.5795 - val_accuracy: 0.7812\n",
      "Epoch 100/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3352 - accuracy: 0.8785 - val_loss: 0.5199 - val_accuracy: 0.7934\n",
      "Epoch 101/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.3541 - accuracy: 0.8702 - val_loss: 0.5360 - val_accuracy: 0.7934\n",
      "Epoch 102/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3319 - accuracy: 0.8737 - val_loss: 0.5719 - val_accuracy: 0.7847\n",
      "Epoch 103/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3365 - accuracy: 0.8750 - val_loss: 0.5646 - val_accuracy: 0.7986\n",
      "Epoch 104/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.3451 - accuracy: 0.8748 - val_loss: 0.5534 - val_accuracy: 0.7986\n",
      "Epoch 105/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3524 - accuracy: 0.8665 - val_loss: 0.4817 - val_accuracy: 0.8194\n",
      "Epoch 106/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3313 - accuracy: 0.8800 - val_loss: 0.4925 - val_accuracy: 0.8021\n",
      "Epoch 107/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3315 - accuracy: 0.8774 - val_loss: 0.6618 - val_accuracy: 0.7552\n",
      "Epoch 108/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3227 - accuracy: 0.8835 - val_loss: 0.5187 - val_accuracy: 0.8090\n",
      "Epoch 109/1000\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.3138 - accuracy: 0.8826 - val_loss: 0.5322 - val_accuracy: 0.8038\n",
      "Epoch 110/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3185 - accuracy: 0.8800 - val_loss: 0.5495 - val_accuracy: 0.7986\n",
      "Epoch 111/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3242 - accuracy: 0.8798 - val_loss: 0.5863 - val_accuracy: 0.7986\n",
      "Epoch 112/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3085 - accuracy: 0.8904 - val_loss: 0.5645 - val_accuracy: 0.7951\n",
      "Epoch 113/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.3134 - accuracy: 0.8848 - val_loss: 0.5258 - val_accuracy: 0.7934\n",
      "Epoch 114/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2973 - accuracy: 0.8924 - val_loss: 0.5971 - val_accuracy: 0.7795\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3271 - accuracy: 0.8785 - val_loss: 0.5456 - val_accuracy: 0.7969\n",
      "Epoch 116/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2902 - accuracy: 0.8969 - val_loss: 0.5010 - val_accuracy: 0.8073\n",
      "Epoch 117/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2996 - accuracy: 0.8906 - val_loss: 0.5386 - val_accuracy: 0.7951\n",
      "Epoch 118/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.3250 - accuracy: 0.8845 - val_loss: 0.5091 - val_accuracy: 0.8003\n",
      "Epoch 119/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.3179 - accuracy: 0.8826 - val_loss: 0.5465 - val_accuracy: 0.7986\n",
      "Epoch 120/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3044 - accuracy: 0.8859 - val_loss: 0.5484 - val_accuracy: 0.7951\n",
      "Epoch 121/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2906 - accuracy: 0.8904 - val_loss: 0.6051 - val_accuracy: 0.7743\n",
      "Epoch 122/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2956 - accuracy: 0.8906 - val_loss: 0.4948 - val_accuracy: 0.8090\n",
      "Epoch 123/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.3060 - accuracy: 0.8874 - val_loss: 0.4837 - val_accuracy: 0.8299\n",
      "Epoch 124/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.3047 - accuracy: 0.8878 - val_loss: 0.5967 - val_accuracy: 0.7812\n",
      "Epoch 125/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2963 - accuracy: 0.8880 - val_loss: 0.5224 - val_accuracy: 0.8073\n",
      "Epoch 126/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2964 - accuracy: 0.8891 - val_loss: 0.4876 - val_accuracy: 0.8108\n",
      "Epoch 127/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2957 - accuracy: 0.8906 - val_loss: 0.5828 - val_accuracy: 0.7899\n",
      "Epoch 128/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2882 - accuracy: 0.8952 - val_loss: 0.5153 - val_accuracy: 0.8108\n",
      "Epoch 129/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2866 - accuracy: 0.8974 - val_loss: 0.6848 - val_accuracy: 0.7691\n",
      "Epoch 130/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.3011 - accuracy: 0.8895 - val_loss: 0.5241 - val_accuracy: 0.8003\n",
      "Epoch 131/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2916 - accuracy: 0.8947 - val_loss: 0.5324 - val_accuracy: 0.7934\n",
      "Epoch 132/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.2969 - accuracy: 0.8926 - val_loss: 0.8906 - val_accuracy: 0.7222\n",
      "Epoch 133/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2930 - accuracy: 0.8937 - val_loss: 0.6007 - val_accuracy: 0.7830\n",
      "Epoch 134/1000\n",
      "72/72 [==============================] - 4s 50ms/step - loss: 0.2858 - accuracy: 0.8941 - val_loss: 0.5845 - val_accuracy: 0.7778\n",
      "Epoch 135/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2786 - accuracy: 0.8915 - val_loss: 0.6985 - val_accuracy: 0.7656\n",
      "Epoch 136/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2733 - accuracy: 0.9021 - val_loss: 0.5757 - val_accuracy: 0.7830\n",
      "Epoch 137/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2917 - accuracy: 0.8980 - val_loss: 0.5593 - val_accuracy: 0.7917\n",
      "Epoch 138/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2729 - accuracy: 0.9008 - val_loss: 0.6256 - val_accuracy: 0.7743\n",
      "Epoch 139/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2891 - accuracy: 0.8945 - val_loss: 0.5025 - val_accuracy: 0.8177\n",
      "Epoch 140/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2799 - accuracy: 0.9004 - val_loss: 0.7218 - val_accuracy: 0.7431\n",
      "Epoch 141/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2942 - accuracy: 0.8904 - val_loss: 0.5128 - val_accuracy: 0.8108\n",
      "Epoch 142/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2815 - accuracy: 0.8978 - val_loss: 0.5722 - val_accuracy: 0.7899\n",
      "Epoch 143/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2724 - accuracy: 0.9049 - val_loss: 0.5470 - val_accuracy: 0.7969\n",
      "Epoch 144/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2691 - accuracy: 0.9028 - val_loss: 0.6740 - val_accuracy: 0.7587\n",
      "Epoch 145/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2682 - accuracy: 0.9015 - val_loss: 0.5523 - val_accuracy: 0.7865\n",
      "Epoch 146/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2839 - accuracy: 0.8965 - val_loss: 0.6276 - val_accuracy: 0.7743\n",
      "Epoch 147/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2683 - accuracy: 0.8980 - val_loss: 0.5783 - val_accuracy: 0.8003\n",
      "Epoch 148/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2776 - accuracy: 0.9039 - val_loss: 0.6895 - val_accuracy: 0.7465\n",
      "Epoch 149/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2630 - accuracy: 0.9036 - val_loss: 0.7275 - val_accuracy: 0.7587\n",
      "Epoch 150/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2587 - accuracy: 0.9067 - val_loss: 0.4974 - val_accuracy: 0.8194\n",
      "Epoch 151/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2673 - accuracy: 0.9002 - val_loss: 0.7601 - val_accuracy: 0.7448\n",
      "Epoch 152/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2716 - accuracy: 0.8987 - val_loss: 0.6744 - val_accuracy: 0.7639\n",
      "Epoch 153/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2626 - accuracy: 0.9030 - val_loss: 0.6098 - val_accuracy: 0.7882\n",
      "Epoch 154/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2768 - accuracy: 0.8969 - val_loss: 0.5495 - val_accuracy: 0.7951\n",
      "Epoch 155/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2845 - accuracy: 0.8934 - val_loss: 0.5624 - val_accuracy: 0.8021\n",
      "Epoch 156/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.2770 - accuracy: 0.9004 - val_loss: 0.5447 - val_accuracy: 0.7934\n",
      "Epoch 157/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.2760 - accuracy: 0.9008 - val_loss: 0.6117 - val_accuracy: 0.7760\n",
      "Epoch 158/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2597 - accuracy: 0.9034 - val_loss: 0.6059 - val_accuracy: 0.7743\n",
      "Epoch 159/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.2643 - accuracy: 0.9021 - val_loss: 0.6318 - val_accuracy: 0.7743\n",
      "Epoch 160/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2707 - accuracy: 0.9026 - val_loss: 0.5383 - val_accuracy: 0.8038\n",
      "Epoch 161/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2493 - accuracy: 0.9084 - val_loss: 0.6318 - val_accuracy: 0.7986\n",
      "Epoch 162/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2573 - accuracy: 0.9054 - val_loss: 0.6917 - val_accuracy: 0.7587\n",
      "Epoch 163/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2603 - accuracy: 0.9056 - val_loss: 0.5541 - val_accuracy: 0.7917\n",
      "Epoch 164/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2551 - accuracy: 0.9043 - val_loss: 0.5695 - val_accuracy: 0.7847\n",
      "Epoch 165/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2456 - accuracy: 0.9099 - val_loss: 0.5751 - val_accuracy: 0.7743\n",
      "Epoch 166/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2521 - accuracy: 0.9043 - val_loss: 0.6393 - val_accuracy: 0.7778\n",
      "Epoch 167/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2404 - accuracy: 0.9123 - val_loss: 0.6243 - val_accuracy: 0.7708\n",
      "Epoch 168/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2476 - accuracy: 0.9117 - val_loss: 0.6893 - val_accuracy: 0.7726\n",
      "Epoch 169/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2513 - accuracy: 0.9054 - val_loss: 0.6414 - val_accuracy: 0.7691\n",
      "Epoch 170/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2427 - accuracy: 0.9099 - val_loss: 0.6456 - val_accuracy: 0.7587\n",
      "Epoch 171/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2309 - accuracy: 0.9119 - val_loss: 0.5796 - val_accuracy: 0.7934\n",
      "Epoch 172/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2401 - accuracy: 0.9123 - val_loss: 0.5617 - val_accuracy: 0.7847\n",
      "Epoch 173/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2368 - accuracy: 0.9145 - val_loss: 0.6064 - val_accuracy: 0.7899\n",
      "Epoch 174/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2355 - accuracy: 0.9151 - val_loss: 0.7121 - val_accuracy: 0.7552\n",
      "Epoch 175/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2517 - accuracy: 0.9106 - val_loss: 0.6781 - val_accuracy: 0.7639\n",
      "Epoch 176/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2434 - accuracy: 0.9121 - val_loss: 0.7227 - val_accuracy: 0.7587\n",
      "Epoch 177/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2454 - accuracy: 0.9121 - val_loss: 0.5464 - val_accuracy: 0.8073\n",
      "Epoch 178/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2560 - accuracy: 0.9065 - val_loss: 0.6407 - val_accuracy: 0.7795\n",
      "Epoch 179/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2463 - accuracy: 0.9132 - val_loss: 0.6454 - val_accuracy: 0.7951\n",
      "Epoch 180/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2328 - accuracy: 0.9132 - val_loss: 0.6173 - val_accuracy: 0.7812\n",
      "Epoch 181/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2415 - accuracy: 0.9104 - val_loss: 0.6556 - val_accuracy: 0.7691\n",
      "Epoch 182/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2430 - accuracy: 0.9084 - val_loss: 0.7083 - val_accuracy: 0.7708\n",
      "Epoch 183/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2391 - accuracy: 0.9108 - val_loss: 0.5622 - val_accuracy: 0.7934\n",
      "Epoch 184/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2349 - accuracy: 0.9151 - val_loss: 0.5890 - val_accuracy: 0.7847\n",
      "Epoch 185/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2367 - accuracy: 0.9104 - val_loss: 0.6189 - val_accuracy: 0.7760\n",
      "Epoch 186/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2420 - accuracy: 0.9132 - val_loss: 0.6650 - val_accuracy: 0.7691\n",
      "Epoch 187/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2250 - accuracy: 0.9210 - val_loss: 0.5966 - val_accuracy: 0.7899\n",
      "Epoch 188/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2350 - accuracy: 0.9145 - val_loss: 0.6490 - val_accuracy: 0.7778\n",
      "Epoch 189/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2315 - accuracy: 0.9143 - val_loss: 0.6175 - val_accuracy: 0.7830\n",
      "Epoch 190/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2246 - accuracy: 0.9160 - val_loss: 0.7472 - val_accuracy: 0.7587\n",
      "Epoch 191/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2321 - accuracy: 0.9145 - val_loss: 0.7891 - val_accuracy: 0.7552\n",
      "Epoch 192/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2311 - accuracy: 0.9119 - val_loss: 0.5779 - val_accuracy: 0.7986\n",
      "Epoch 193/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2308 - accuracy: 0.9141 - val_loss: 0.5437 - val_accuracy: 0.8177\n",
      "Epoch 194/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2218 - accuracy: 0.9173 - val_loss: 0.5238 - val_accuracy: 0.8160\n",
      "Epoch 195/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2271 - accuracy: 0.9208 - val_loss: 0.5509 - val_accuracy: 0.7934\n",
      "Epoch 196/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2325 - accuracy: 0.9151 - val_loss: 0.5839 - val_accuracy: 0.7917\n",
      "Epoch 197/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2137 - accuracy: 0.9240 - val_loss: 0.6297 - val_accuracy: 0.7865\n",
      "Epoch 198/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2238 - accuracy: 0.9141 - val_loss: 0.6381 - val_accuracy: 0.7899\n",
      "Epoch 199/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2135 - accuracy: 0.9182 - val_loss: 0.5542 - val_accuracy: 0.8056\n",
      "Epoch 200/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2325 - accuracy: 0.9147 - val_loss: 0.5604 - val_accuracy: 0.7917\n",
      "Epoch 201/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2297 - accuracy: 0.9154 - val_loss: 0.6543 - val_accuracy: 0.7760\n",
      "Epoch 202/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2270 - accuracy: 0.9182 - val_loss: 0.6139 - val_accuracy: 0.7812\n",
      "Epoch 203/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2361 - accuracy: 0.9115 - val_loss: 0.5604 - val_accuracy: 0.8056\n",
      "Epoch 204/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2357 - accuracy: 0.9091 - val_loss: 0.6858 - val_accuracy: 0.7622\n",
      "Epoch 205/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2217 - accuracy: 0.9178 - val_loss: 0.6332 - val_accuracy: 0.7830\n",
      "Epoch 206/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2259 - accuracy: 0.9164 - val_loss: 0.6035 - val_accuracy: 0.7986\n",
      "Epoch 207/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2129 - accuracy: 0.9280 - val_loss: 0.6544 - val_accuracy: 0.7778\n",
      "Epoch 208/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2277 - accuracy: 0.9178 - val_loss: 0.6652 - val_accuracy: 0.7587\n",
      "Epoch 209/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2218 - accuracy: 0.9208 - val_loss: 0.6548 - val_accuracy: 0.7691\n",
      "Epoch 210/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2165 - accuracy: 0.9223 - val_loss: 0.7409 - val_accuracy: 0.7604\n",
      "Epoch 211/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2143 - accuracy: 0.9225 - val_loss: 0.6228 - val_accuracy: 0.7812\n",
      "Epoch 212/1000\n",
      "72/72 [==============================] - 3s 42ms/step - loss: 0.2108 - accuracy: 0.9236 - val_loss: 0.5562 - val_accuracy: 0.7882\n",
      "Epoch 213/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2352 - accuracy: 0.9138 - val_loss: 0.6374 - val_accuracy: 0.7882\n",
      "Epoch 214/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2200 - accuracy: 0.9169 - val_loss: 0.7272 - val_accuracy: 0.7674\n",
      "Epoch 215/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.2209 - accuracy: 0.9171 - val_loss: 0.8186 - val_accuracy: 0.7431\n",
      "Epoch 216/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2107 - accuracy: 0.9262 - val_loss: 0.6340 - val_accuracy: 0.7847\n",
      "Epoch 217/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2203 - accuracy: 0.9212 - val_loss: 0.5658 - val_accuracy: 0.7847\n",
      "Epoch 218/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2107 - accuracy: 0.9217 - val_loss: 0.6349 - val_accuracy: 0.7917\n",
      "Epoch 219/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2183 - accuracy: 0.9217 - val_loss: 0.6357 - val_accuracy: 0.7812\n",
      "Epoch 220/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2181 - accuracy: 0.9197 - val_loss: 0.6495 - val_accuracy: 0.7760\n",
      "Epoch 221/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2083 - accuracy: 0.9273 - val_loss: 0.5546 - val_accuracy: 0.7986\n",
      "Epoch 222/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2139 - accuracy: 0.9208 - val_loss: 0.6530 - val_accuracy: 0.7760\n",
      "Epoch 223/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2208 - accuracy: 0.9234 - val_loss: 0.5861 - val_accuracy: 0.7969\n",
      "Epoch 224/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2052 - accuracy: 0.9301 - val_loss: 0.5761 - val_accuracy: 0.7934\n",
      "Epoch 225/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1868 - accuracy: 0.9345 - val_loss: 0.7281 - val_accuracy: 0.7569\n",
      "Epoch 226/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2058 - accuracy: 0.9251 - val_loss: 0.6324 - val_accuracy: 0.7778\n",
      "Epoch 227/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1979 - accuracy: 0.9284 - val_loss: 0.6454 - val_accuracy: 0.7691\n",
      "Epoch 228/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2054 - accuracy: 0.9297 - val_loss: 0.5508 - val_accuracy: 0.7969\n",
      "Epoch 229/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2291 - accuracy: 0.9149 - val_loss: 0.7298 - val_accuracy: 0.7743\n",
      "Epoch 230/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2056 - accuracy: 0.9273 - val_loss: 0.6550 - val_accuracy: 0.7778\n",
      "Epoch 231/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2111 - accuracy: 0.9251 - val_loss: 0.6110 - val_accuracy: 0.7865\n",
      "Epoch 232/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2024 - accuracy: 0.9288 - val_loss: 0.5245 - val_accuracy: 0.8229\n",
      "Epoch 233/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2058 - accuracy: 0.9227 - val_loss: 0.6921 - val_accuracy: 0.7795\n",
      "Epoch 234/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2085 - accuracy: 0.9223 - val_loss: 0.6169 - val_accuracy: 0.7899\n",
      "Epoch 235/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2081 - accuracy: 0.9204 - val_loss: 0.6105 - val_accuracy: 0.7951\n",
      "Epoch 236/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2134 - accuracy: 0.9221 - val_loss: 0.6430 - val_accuracy: 0.7812\n",
      "Epoch 237/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2125 - accuracy: 0.9206 - val_loss: 0.8687 - val_accuracy: 0.7344\n",
      "Epoch 238/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2036 - accuracy: 0.9251 - val_loss: 0.6908 - val_accuracy: 0.7743\n",
      "Epoch 239/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1991 - accuracy: 0.9280 - val_loss: 0.6905 - val_accuracy: 0.7726\n",
      "Epoch 240/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1967 - accuracy: 0.9282 - val_loss: 0.6256 - val_accuracy: 0.7951\n",
      "Epoch 241/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1913 - accuracy: 0.9308 - val_loss: 0.7224 - val_accuracy: 0.7622\n",
      "Epoch 242/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2019 - accuracy: 0.9282 - val_loss: 0.6153 - val_accuracy: 0.7778\n",
      "Epoch 243/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.2089 - accuracy: 0.9266 - val_loss: 0.8094 - val_accuracy: 0.7569\n",
      "Epoch 244/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.2041 - accuracy: 0.9275 - val_loss: 0.7651 - val_accuracy: 0.7656\n",
      "Epoch 245/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2131 - accuracy: 0.9247 - val_loss: 0.7630 - val_accuracy: 0.7552\n",
      "Epoch 246/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1956 - accuracy: 0.9308 - val_loss: 0.6487 - val_accuracy: 0.7882\n",
      "Epoch 247/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2059 - accuracy: 0.9243 - val_loss: 0.6320 - val_accuracy: 0.7812\n",
      "Epoch 248/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.2072 - accuracy: 0.9253 - val_loss: 0.7104 - val_accuracy: 0.7674\n",
      "Epoch 249/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1880 - accuracy: 0.9301 - val_loss: 0.6076 - val_accuracy: 0.7969\n",
      "Epoch 250/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1921 - accuracy: 0.9319 - val_loss: 0.6276 - val_accuracy: 0.7812\n",
      "Epoch 251/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.1870 - accuracy: 0.9321 - val_loss: 0.6740 - val_accuracy: 0.7830\n",
      "Epoch 252/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1990 - accuracy: 0.9266 - val_loss: 0.8342 - val_accuracy: 0.7500\n",
      "Epoch 253/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1955 - accuracy: 0.9282 - val_loss: 0.7087 - val_accuracy: 0.7726\n",
      "Epoch 254/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1810 - accuracy: 0.9360 - val_loss: 0.7285 - val_accuracy: 0.7604\n",
      "Epoch 255/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1978 - accuracy: 0.9312 - val_loss: 0.7263 - val_accuracy: 0.7674\n",
      "Epoch 256/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1910 - accuracy: 0.9290 - val_loss: 0.7898 - val_accuracy: 0.7465\n",
      "Epoch 257/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1860 - accuracy: 0.9303 - val_loss: 0.7108 - val_accuracy: 0.7604\n",
      "Epoch 258/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.2035 - accuracy: 0.9230 - val_loss: 0.6263 - val_accuracy: 0.7830\n",
      "Epoch 259/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.2056 - accuracy: 0.9243 - val_loss: 0.6465 - val_accuracy: 0.7847\n",
      "Epoch 260/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1908 - accuracy: 0.9308 - val_loss: 0.7284 - val_accuracy: 0.7708\n",
      "Epoch 261/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1938 - accuracy: 0.9301 - val_loss: 0.7102 - val_accuracy: 0.7639\n",
      "Epoch 262/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.2065 - accuracy: 0.9219 - val_loss: 0.7815 - val_accuracy: 0.7622\n",
      "Epoch 263/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1880 - accuracy: 0.9286 - val_loss: 0.7024 - val_accuracy: 0.7656\n",
      "Epoch 264/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1876 - accuracy: 0.9314 - val_loss: 0.6890 - val_accuracy: 0.7934\n",
      "Epoch 265/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1925 - accuracy: 0.9280 - val_loss: 0.6375 - val_accuracy: 0.7882\n",
      "Epoch 266/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1839 - accuracy: 0.9349 - val_loss: 0.6120 - val_accuracy: 0.7882\n",
      "Epoch 267/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1960 - accuracy: 0.9277 - val_loss: 0.6593 - val_accuracy: 0.7778\n",
      "Epoch 268/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1779 - accuracy: 0.9347 - val_loss: 0.6101 - val_accuracy: 0.7847\n",
      "Epoch 269/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1832 - accuracy: 0.9332 - val_loss: 0.7482 - val_accuracy: 0.7639\n",
      "Epoch 270/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1822 - accuracy: 0.9319 - val_loss: 0.7392 - val_accuracy: 0.7639\n",
      "Epoch 271/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1980 - accuracy: 0.9271 - val_loss: 0.7091 - val_accuracy: 0.7812\n",
      "Epoch 272/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1888 - accuracy: 0.9284 - val_loss: 0.7047 - val_accuracy: 0.7743\n",
      "Epoch 273/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1933 - accuracy: 0.9306 - val_loss: 0.6976 - val_accuracy: 0.7865\n",
      "Epoch 274/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1761 - accuracy: 0.9349 - val_loss: 0.6556 - val_accuracy: 0.7812\n",
      "Epoch 275/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1820 - accuracy: 0.9355 - val_loss: 0.7291 - val_accuracy: 0.7726\n",
      "Epoch 276/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1872 - accuracy: 0.9332 - val_loss: 0.6549 - val_accuracy: 0.7865\n",
      "Epoch 277/1000\n",
      "72/72 [==============================] - 3s 46ms/step - loss: 0.1810 - accuracy: 0.9366 - val_loss: 0.7109 - val_accuracy: 0.7795\n",
      "Epoch 278/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1887 - accuracy: 0.9306 - val_loss: 0.6529 - val_accuracy: 0.7760\n",
      "Epoch 279/1000\n",
      "72/72 [==============================] - 3s 49ms/step - loss: 0.1778 - accuracy: 0.9338 - val_loss: 0.6258 - val_accuracy: 0.7847\n",
      "Epoch 280/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1812 - accuracy: 0.9384 - val_loss: 0.7948 - val_accuracy: 0.7552\n",
      "Epoch 281/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1903 - accuracy: 0.9314 - val_loss: 0.7653 - val_accuracy: 0.7552\n",
      "Epoch 282/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1835 - accuracy: 0.9329 - val_loss: 0.8841 - val_accuracy: 0.7361\n",
      "Epoch 283/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1845 - accuracy: 0.9336 - val_loss: 0.8217 - val_accuracy: 0.7535\n",
      "Epoch 284/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1867 - accuracy: 0.9295 - val_loss: 0.6377 - val_accuracy: 0.7812\n",
      "Epoch 285/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1714 - accuracy: 0.9371 - val_loss: 0.7225 - val_accuracy: 0.7656\n",
      "Epoch 286/1000\n",
      "72/72 [==============================] - 3s 43ms/step - loss: 0.1787 - accuracy: 0.9368 - val_loss: 0.6258 - val_accuracy: 0.8108\n",
      "Epoch 287/1000\n",
      "72/72 [==============================] - 3s 47ms/step - loss: 0.1913 - accuracy: 0.9301 - val_loss: 0.6920 - val_accuracy: 0.7812\n",
      "Epoch 288/1000\n",
      "72/72 [==============================] - 3s 48ms/step - loss: 0.1888 - accuracy: 0.9280 - val_loss: 0.7095 - val_accuracy: 0.7899\n",
      "Epoch 289/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1900 - accuracy: 0.9308 - val_loss: 0.6934 - val_accuracy: 0.7778\n",
      "Epoch 290/1000\n",
      "72/72 [==============================] - 3s 44ms/step - loss: 0.1837 - accuracy: 0.9334 - val_loss: 1.0186 - val_accuracy: 0.7396\n",
      "Epoch 291/1000\n",
      "72/72 [==============================] - 4s 49ms/step - loss: 0.1920 - accuracy: 0.9308 - val_loss: 0.8175 - val_accuracy: 0.7587\n",
      "Epoch 292/1000\n",
      "72/72 [==============================] - 3s 45ms/step - loss: 0.1780 - accuracy: 0.9345 - val_loss: 0.6646 - val_accuracy: 0.7847\n",
      "Epoch 293/1000\n",
      "42/72 [================>.............] - ETA: 1s - loss: 0.1749 - accuracy: 0.9394"
     ]
    }
   ],
   "source": [
    "from main import *\n",
    "train_sub = [1,2,4,5,6,7,8,9]\n",
    "val_sub = [3]\n",
    "test_sub = [3]\n",
    "\n",
    "train_without_aug(train_sub, val_sub, test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "circular-butterfly",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_sub = [2,3,4,5,6,7,8,9]\n",
    "val_sub = [1]\n",
    "test_sub = [1]\n",
    "\n",
    "train_without_aug(train_sub, val_sub, test_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "everyday-mountain",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
